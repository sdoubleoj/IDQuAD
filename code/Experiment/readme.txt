This folder contains the experimental code used to evaluate the performance of Mistral and GPT models on the IDQuAD dataset. The core experimental code is provided for these two models, while the experiments for other models (e.g., Gemma) were conducted using the same codebase. But, for Llama and Alpaca, we added simple prompts such as "The answer should be extracted directly from the context" to tailor the task for those models.